{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-12T17:04:35.689500Z",
     "start_time": "2024-11-12T17:04:35.631067Z"
    }
   },
   "source": [
    "# Autoreload possibly interferes with IntelliJ debugging\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "log = lambda msg: logging.info(msg)\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T17:04:36.421668Z",
     "start_time": "2024-11-12T17:04:35.879596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "input_dir = \"C:\\\\dev\\\\play\\\\brainwave-data\"\n",
    "stats_df = pd.read_csv(input_dir + os.path.sep + \"stats.csv\")"
   ],
   "id": "69fc66b1853d1db9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "import run_feature_pipeline\n",
    "errors = []\n",
    "\n",
    "dfs = []\n",
    "sleep_json_dfs = []\n",
    "# Could get these working later\n",
    "skip_list = ['2024-07-23-22-40-25', '2024-07-28-22-29-49', '2024-09-18-21-25-08', '2024-09-18-21-28-11', '2024-09-19-21-29-42']\n",
    "\n",
    "\n",
    "def flatten_json(y):\n",
    "    out = {}\n",
    "\n",
    "    def flatten(x, name=''):\n",
    "        if type(x) is dict:\n",
    "            for a in x:\n",
    "                flatten(x[a], name + a + '_')\n",
    "        elif type(x) is list:\n",
    "            i = 0\n",
    "            for a in x:\n",
    "                flatten(a, name + str(i) + '_')\n",
    "                i += 1\n",
    "        else:\n",
    "            out[name[:-1]] = x\n",
    "\n",
    "    flatten(y)\n",
    "    return out\n",
    "\n",
    "for root, dirs, files in os.walk(input_dir):\n",
    "    for idx, dir_name in enumerate(dirs):\n",
    "        input_file = os.path.join(root, dir_name, \"raw.fif\")\n",
    "        if dir_name in skip_list:\n",
    "            log(f\"Skipping {idx} of {len(dirs)}: \" + input_file)\n",
    "            continue\n",
    "\n",
    "\n",
    "        json_file = os.path.join(root, dir_name, \"raw.sleep.json\")\n",
    "        try:\n",
    "            if os.path.exists(json_file):\n",
    "                with open(json_file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    flat_data = flatten_json(data)\n",
    "                    flat_data['dir_name'] = dir_name\n",
    "                    sleep_json_dfs.append(pd.DataFrame([flat_data]))\n",
    "        except Exception as e:\n",
    "            log(\"Error processing file: \" + json_file)\n",
    "            errors.append(\"Error processing file: \" + json_file + \" - \" + str(e))\n",
    "            log(e)\n",
    "\n",
    "        try:\n",
    "            log(\"Processing file: \" + input_file)\n",
    "\n",
    "            if os.path.exists(input_file):\n",
    "                # day_and_night_of_date = datetime.strptime(dir_name, \"%Y-%m-%d\")\n",
    "                day_and_night_of_date = datetime.strptime(dir_name, \"%Y-%m-%d-%H-%M-%S\")\n",
    "                day_and_night_of = day_and_night_of_date.date().isoformat()\n",
    "                %%capture captured\n",
    "                yasa_df = run_feature_pipeline.cached_pipeline(log, input_file, stats_df)\n",
    "                yasa_df['dayAndNightOf'] = day_and_night_of\n",
    "                dfs.append(yasa_df)\n",
    "        except Exception as e:\n",
    "            log(\"Error processing file: \" + input_file)\n",
    "            errors.append(\"Error processing file: \" + input_file + \" - \" + str(e))\n",
    "            log(e)\n",
    "\n",
    "for err in errors:\n",
    "    log(err)\n",
    "\n",
    "sleep_json_df = pd.concat(sleep_json_dfs)\n",
    "\n",
    "yasa_df = pd.concat(dfs)\n",
    "yasa_df"
   ],
   "id": "b59d3e6f8b3fe4df",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 17:11:12,648 - INFO - Writing to C:\\dev\\play\\brainwave-data\\2024-10-04-21-13-39\\raw.sleep_stages.csv\n",
      "2024-11-12 17:11:12,864 - INFO - Memory Usage: 6656.37 MB GC to 6656.37 MB\n",
      "2024-11-12 17:11:12,865 - INFO - Processing sleep statistics\n",
      "2024-11-12 17:11:13,072 - INFO - Memory Usage: 6656.37 MB GC to 6656.37 MB\n",
      "2024-11-12 17:11:13,073 - INFO - Processing sleep stability\n",
      "2024-11-12 17:11:13,308 - INFO - Memory Usage: 6656.37 MB GC to 6656.37 MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up band-pass filter from 0.3 - 1.5 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.30\n",
      "- Lower transition bandwidth: 0.20 Hz (-6 dB cutoff frequency: 0.20 Hz)\n",
      "- Upper passband edge: 1.50 Hz\n",
      "- Upper transition bandwidth: 0.20 Hz (-6 dB cutoff frequency: 1.60 Hz)\n",
      "- Filter length: 4125 samples (16.500 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 17:11:19,667 - INFO - Memory Usage: 6699.30 MB GC to 6666.54 MB\n",
      "2024-11-12 17:11:19,670 - INFO - YASA all done!\n",
      "2024-11-12 17:11:19,909 - INFO - Memory Usage: 6602.50 MB GC to 6602.50 MB\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "2024-11-12 17:11:20,125 - INFO - Memory Usage: 6603.68 MB GC to 6603.68 MB\n",
      "2024-11-12 17:11:20,126 - INFO - Automated waking scoring\n",
      "2024-11-12 17:11:20,388 - INFO - Memory Usage: 6605.46 MB GC to 6605.46 MB\n",
      "2024-11-12 17:11:20,389 - INFO - Manual waking scoring\n",
      "2024-11-12 17:11:21,284 - INFO - Memory Usage: 6608.01 MB GC to 6608.01 MB\n",
      "2024-11-12 17:11:21,285 - INFO - Epochs that are probably sleep\n",
      "2024-11-12 17:11:21,854 - INFO - Memory Usage: 6609.84 MB GC to 6609.79 MB\n",
      "2024-11-12 17:11:21,854 - INFO - Running microwakings model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 655ms/step\n",
      "Saved microwakings to: C:\\dev\\play\\brainwave-data\\2024-10-04-21-13-39\\raw.microwakings.csv\n",
      "Channel\n",
      "(1, 8131377)\n",
      "0\n",
      "Padding needed 2\n",
      "8131377\n",
      "Upsampled channel: 8131377\n",
      "Orig (1, 8131377)\n",
      "(1, 8131377)\n",
      "1\n",
      "8131377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 17:11:26,524 - INFO - Exporting to: C:\\dev\\play\\brainwave-data\\2024-10-04-21-13-39\\raw.edf\n",
      "2024-11-12 17:11:27,318 - INFO - All done! C:\\dev\\play\\brainwave-data\\2024-10-04-21-13-39\\raw.fif\n",
      "2024-11-12 17:11:27,331 - INFO - Processing file: C:\\dev\\play\\brainwave-data\\2024-10-05-21-09-46\\raw.fif\n",
      "2024-11-12 17:11:27,333 - INFO - Loading cached file C:\\dev\\play\\brainwave-data\\2024-10-05-21-09-46\\raw.with_features.csv\n",
      "2024-11-12 17:11:27,382 - INFO - Cached file C:\\dev\\play\\brainwave-data\\2024-10-05-21-09-46\\raw.with_features.csv mod date 2024-11-08 18:39:48.763317 is < 2024-11-11 13:30:00, rebuilding\n",
      "2024-11-12 17:11:27,383 - INFO - Loading MNE file C:\\dev\\play\\brainwave-data\\2024-10-05-21-09-46\\raw.fif\n",
      "2024-11-12 17:11:27,383 - INFO - Reading file C:\\dev\\play\\brainwave-data\\2024-10-05-21-09-46\\raw.fif\n",
      "2024-11-12 17:11:27,995 - INFO - Finished reading file C:\\dev\\play\\brainwave-data\\2024-10-05-21-09-46\\raw.fif\n",
      "2024-11-12 17:11:28,730 - INFO - Start date: 2024-10-05 20:09:46.500000+00:00 channels: ['Fpz-M1'] sfreq: 250.0\n",
      "2024-11-12 17:11:28,965 - INFO - Memory Usage: 6558.22 MB GC to 6558.20 MB\n",
      "2024-11-12 17:11:28,965 - INFO - Saving as EDF\n",
      "2024-11-12 17:11:31,297 - INFO - Memory Usage: 6561.92 MB GC to 6561.92 MB\n",
      "2024-11-12 17:11:31,297 - INFO - Loading sleep events\n",
      "C:\\dev\\play\\brainwave-processor\\sleep_events.py:33: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  ha_events_for_file = ha_events[ha_events['timestamp'] >= start_date][ha_events['timestamp'] <= end_date][ha_events['event'] == 'wake']\n",
      "C:\\dev\\play\\brainwave-processor\\sleep_events.py:33: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  ha_events_for_file = ha_events[ha_events['timestamp'] >= start_date][ha_events['timestamp'] <= end_date][ha_events['event'] == 'wake']\n",
      "2024-11-12 17:11:31,905 - INFO - Memory Usage: 6561.92 MB GC to 6560.92 MB\n",
      "2024-11-12 17:11:31,906 - INFO - Extracting YASA features\n",
      "2024-11-12 17:11:34,537 - INFO - Memory Usage: 6562.52 MB GC to 6562.52 MB\n",
      "2024-11-12 17:11:34,537 - INFO - Detecting slow waves\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up band-pass filter from 0.3 - 1.5 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.30\n",
      "- Lower transition bandwidth: 0.20 Hz (-6 dB cutoff frequency: 0.20 Hz)\n",
      "- Upper passband edge: 1.50 Hz\n",
      "- Upper transition bandwidth: 0.20 Hz (-6 dB cutoff frequency: 1.60 Hz)\n",
      "- Filter length: 4125 samples (16.500 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 17:11:35,398 - INFO - Memory Usage: 6691.82 MB GC to 6691.82 MB\n",
      "2024-11-12 17:11:35,398 - INFO - Running YASA\n",
      "2024-11-12 17:11:35,592 - INFO - Memory Usage: 6691.82 MB GC to 6691.82 MB\n",
      "2024-11-12 17:11:39,449 - WARNING - Hypnogram is SHORTER than data by 25.35 seconds. Padding hypnogram with last value to match data.size.\n",
      "2024-11-12 17:11:48,149 - INFO - Writing to C:\\dev\\play\\brainwave-data\\2024-10-05-21-09-46\\raw.sleep_stages.csv\n",
      "2024-11-12 17:11:48,357 - INFO - Memory Usage: 6869.95 MB GC to 6869.95 MB\n",
      "2024-11-12 17:11:48,357 - INFO - Processing sleep statistics\n",
      "2024-11-12 17:11:48,553 - INFO - Memory Usage: 6869.95 MB GC to 6869.95 MB\n",
      "2024-11-12 17:11:48,554 - INFO - Processing sleep stability\n",
      "2024-11-12 17:11:48,752 - INFO - Memory Usage: 6869.95 MB GC to 6869.95 MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up band-pass filter from 0.3 - 1.5 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.30\n",
      "- Lower transition bandwidth: 0.20 Hz (-6 dB cutoff frequency: 0.20 Hz)\n",
      "- Upper passband edge: 1.50 Hz\n",
      "- Upper transition bandwidth: 0.20 Hz (-6 dB cutoff frequency: 1.60 Hz)\n",
      "- Filter length: 4125 samples (16.500 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 17:11:56,112 - INFO - Memory Usage: 6913.62 MB GC to 6878.54 MB\n",
      "2024-11-12 17:11:56,114 - INFO - YASA all done!\n",
      "2024-11-12 17:11:56,344 - INFO - Memory Usage: 6813.89 MB GC to 6813.89 MB\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "C:\\dev\\play\\brainwave-processor\\scaling.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[renamed] = df[col]\n",
      "2024-11-12 17:11:56,575 - INFO - Memory Usage: 6815.12 MB GC to 6815.12 MB\n",
      "2024-11-12 17:11:56,576 - INFO - Automated waking scoring\n",
      "2024-11-12 17:11:56,807 - INFO - Memory Usage: 6816.97 MB GC to 6816.97 MB\n",
      "2024-11-12 17:11:56,808 - INFO - Manual waking scoring\n",
      "2024-11-12 17:11:57,489 - INFO - Memory Usage: 6820.68 MB GC to 6820.68 MB\n",
      "2024-11-12 17:11:57,490 - INFO - Epochs that are probably sleep\n",
      "2024-11-12 17:11:58,048 - INFO - Memory Usage: 6822.53 MB GC to 6822.53 MB\n",
      "2024-11-12 17:11:58,049 - INFO - Running microwakings model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 758ms/step\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sleep_json_df",
   "id": "32b6824c26d8967",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "[col for col in sleep_json_df.columns if 'sigmaabsaa_s' in col]",
   "id": "888c3bfb5b7149fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sleep_json_df[['Fpz_eeg_sigmaabs_aa_s', 'dir_name']]",
   "id": "b3ffc01c83431029",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sleep_json_df['SlowWaves_Fpz-M1_PTP'].describe()\n",
   "id": "8b86204c4efaa4df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "459a10d896a44625",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
