{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Score Morning Light\n",
    "See what morning light does and if I can produce an aggregate score."
   ],
   "id": "39eab6d0f764f1b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import run_yasa\n",
    "import logging\n",
    "import mne\n",
    "import yasa\n",
    "import os\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from brainflow.board_shim import BoardShim, BoardIds\n",
    "from brainflow.data_filter import DataFilter\n",
    "\n",
    "log = lambda msg: logging.info(msg)\n"
   ],
   "id": "9178a795b416a375",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load data",
   "id": "2c083832d6852a80"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "input_dir = \"C:\\\\dev\\\\play\\\\brainwave-data\"\n",
    "stats_df = pd.read_csv(input_dir + os.path.sep + \"stats.csv\")\n"
   ],
   "id": "25a4057018ffbb1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "63e6e8cb153f55cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from sleep_events import connect_to_firebase\n",
    "\n",
    "# def load_sleep_events(log, start_date, end_date, waking_start_time_tz, waking_end_time_tz):\n",
    "db = connect_to_firebase()\n",
    "\n",
    "docs = db.collection('daysExperimental').stream()\n",
    "\n",
    "# Convert to list of dictionaries\n",
    "records = [doc.to_dict() for doc in docs]\n",
    "\n",
    "days = pd.DataFrame(records)\n",
    "days"
   ],
   "id": "3e691d6351de00fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import json\n",
    "\n",
    "df = days\n",
    "# Assuming yasa_df is your DataFrame and 'ML' is the column containing JSON data\n",
    "json_column = 'ml'\n",
    "\n",
    "# Explode the JSON column into separate columns\n",
    "exploded_df = json_normalize(df[json_column])\n",
    "\n",
    "# Merge the new DataFrame with the 'dayAndNightOf' column\n",
    "result_df = pd.concat([df['dayAndNightOf'], exploded_df], axis=1)\n",
    "\n",
    "# Drop all other columns except 'dayAndNightOf' and the new columns from the JSON data\n",
    "result_df = result_df.loc[:, ~result_df.columns.duplicated()]\n"
   ],
   "id": "90b5553b79304ad9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "result_df",
   "id": "3a9fd1eddfcd22ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Add score\n",
    "\n",
    "I'm trying to get the last evening peak (LEP) of my core body temperature to 21:45.  If the LEP is close to there and doesn't move that's good.  If the LEP is far away but moves towards the target (particularly rapidly) that is also good.  How to come up with a single score that represents both goals?"
   ],
   "id": "3ce247cc9e857954"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calculate_lep_score(current_lep_ssm, lep_delta_seconds, target_lep_ssm=78300):  # 21:45 = 21*3600 + 45*60 = 78300\n",
    "    # Constants\n",
    "    SECONDS_PER_DAY = 24 * 60 * 60\n",
    "    MAX_DIFFERENCE = SECONDS_PER_DAY // 12  # Maximum difference is 2 hours\n",
    "\n",
    "    # Calculate proximity score (0 to 100)\n",
    "    current_difference = min(abs(current_lep_ssm - target_lep_ssm),\n",
    "                             SECONDS_PER_DAY - abs(current_lep_ssm - target_lep_ssm))\n",
    "    proximity_score = 100 * (1 - current_difference / MAX_DIFFERENCE)\n",
    "\n",
    "    # Calculate improvement score (-100 to 100)\n",
    "    target_change = (target_lep_ssm - (current_lep_ssm - lep_delta_seconds) + SECONDS_PER_DAY // 2) % SECONDS_PER_DAY - SECONDS_PER_DAY // 2\n",
    "\n",
    "    if lep_delta_seconds == 0 or target_change == 0:\n",
    "        improvement_score = 0\n",
    "    elif (lep_delta_seconds > 0) == (target_change > 0):  # Moving in the right direction\n",
    "        improvement_score = min(100, abs(lep_delta_seconds / target_change) * 100)\n",
    "    else:  # Moving in the wrong direction\n",
    "        improvement_score = -min(100, abs(lep_delta_seconds / target_change) * 100)\n",
    "\n",
    "    # Combine scores (adjust weights as needed)\n",
    "    proximity_weight = 0.6\n",
    "    improvement_weight = 0.4\n",
    "    final_score = proximity_weight * proximity_score + improvement_weight * improvement_score\n",
    "\n",
    "    return final_score\n",
    "\n",
    "# Helper function to convert time to SSM\n",
    "def time_to_ssm(hours, minutes, seconds=0):\n",
    "    return hours * 3600 + minutes * 60 + seconds\n",
    "\n",
    "# Helper function to convert SSM to time string\n",
    "def ssm_to_time_string(ssm):\n",
    "    hours, remainder = divmod(ssm, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    return f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
    "\n",
    "# Example usage\n",
    "current_lep_ssm = time_to_ssm(22, 30)  # 22:30:00\n",
    "lep_delta_seconds = -1800  # Moved 30 minutes earlier (negative because it's closer to target)\n",
    "target_lep_ssm = time_to_ssm(21, 45)  # 21:45:00\n",
    "score = calculate_lep_score(current_lep_ssm, lep_delta_seconds, target_lep_ssm)\n",
    "print(f\"Current LEP: {ssm_to_time_string(current_lep_ssm)}\")\n",
    "print(f\"Delta: {lep_delta_seconds} seconds\")\n",
    "print(f\"Target LEP: {ssm_to_time_string(target_lep_ssm)}\")\n",
    "print(f\"LEP Score: {score:.2f}\")\n",
    "\n",
    "# Additional examples\n",
    "print(\"\\nAdditional Examples:\")\n",
    "print(f\"Score for 21:45:00 (no change): {calculate_lep_score(time_to_ssm(21, 45), 0):.2f}\")\n",
    "print(f\"Score for 22:00:00 (15 min later): {calculate_lep_score(time_to_ssm(22, 0), 900):.2f}\")\n",
    "print(f\"Score for 21:30:00 (15 min earlier): {calculate_lep_score(time_to_ssm(21, 30), -900):.2f}\")\n",
    "print(f\"Score for 23:00:00 (30 min later): {calculate_lep_score(time_to_ssm(23, 0), 1800):.2f}\")\n",
    "print(f\"Score for 21:45:00 (at target, moved 15 min later): {calculate_lep_score(time_to_ssm(21, 45), 900):.2f}\")"
   ],
   "id": "cab7e0e86bcc0353",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "\n",
    "def apply_lep_score(row):\n",
    "    return calculate_lep_score(row['circadian:combined:entries:LEP:datetimeSSM'], row['circadian:combined:entries:LEP:datetimeSSM:vsDayMinus1'])\n",
    "\n",
    "# Apply the function to each row\n",
    "result_df['lep_score'] = result_df.apply(apply_lep_score, axis=1)\n",
    "\n",
    "def ssm_to_hhmm(ssm):\n",
    "    if pd.isna(ssm):\n",
    "        return None\n",
    "    ssm = int(ssm)  # Convert to integer\n",
    "    hours, remainder = divmod(ssm, 3600)\n",
    "    minutes, _ = divmod(remainder, 60)\n",
    "    return f\"{hours:02d}:{minutes:02d}\"\n",
    "\n",
    "result_df['LEP_HHMM'] = result_df['circadian:combined:entries:LEP:datetimeSSM'].apply(ssm_to_hhmm)\n",
    "\n",
    "\n",
    "# Display the updated DataFrame\n",
    "results = result_df[['circadian:combined:entries:LEP:datetimeSSM', 'circadian:combined:entries:LEP:datetimeSSM:vsDayMinus1', 'LEP_HHMM', 'lep_score']]\n",
    "results[~results['lep_score'].isna()]"
   ],
   "id": "31134e81449c5f88",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prepare data",
   "id": "fbad9e49c04d9ae0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 21:45 should get us asleep about 22:15 and waking about 06:15\n",
    "# It's kind of arbritrary but it's a good starting point\n",
    "ideal_lep_ssm = 21*60*60 + 45*60\n",
    "result_df['lep_mins_from_ideal_lep'] = (result_df['circadian:basic:entries:LEP:datetimeSSM'] - ideal_lep_ssm) / 60\n",
    "result_df['lep_mins_from_ideal_lep'].describe()"
   ],
   "id": "f8e891a706bd01fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "[col for col in result_df.columns if\n",
    " (\"sun\" in col or \"LEP\" in col or \"lightDuringFirstTimeOutside\" in col) and \"DayMinus\" not in col]"
   ],
   "id": "c2c4b3b11c2998a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "interesting_causes = ['sunrise:sunsetEndSSM',\n",
    "                      'sunExposure:firstEnteredOutsideSSM',\n",
    "                      'sunExposureCombined:betweenWakeAndFirstSun',\n",
    "                      'sunExposure:totalTimeOutsideSecs',\n",
    "                      'sunExposure:firstDurationOutside',\n",
    "                      'events:shower:lastSSM',\n",
    "                      'sunExposure:lightDuringFirstTimeOutside',\n",
    "                      ]\n",
    "\n",
    "interesting_effects = ['circadian:basic:entries:LEP:prominence',\n",
    "                       'circadian:combined:entries:LEP:temp',\n",
    "                       'circadian:basic:entries:LEP:datetimeSSM',\n",
    "                       'circadian:basic:entries:LEP:datetimeSSM:vsDayMinus1',\n",
    "                       'lep_mins_from_ideal_lep'\n",
    "                       ]\n",
    "\n",
    "filtered_df = result_df[interesting_causes + interesting_effects]\n",
    "filtered_df"
   ],
   "id": "92da31c52cfb0282",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "filtered_df[~filtered_df['circadian:basic:entries:LEP:datetimeSSM'].isna()]['lep_mins_from_ideal_lep'].plot()",
   "id": "5e52993e813a1346",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "filtered_df['lep_mins_from_ideal_lep'].describe()",
   "id": "ae7f328b0a9826ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming result_df is your DataFrame\n",
    "X = result_df.drop(columns=['lep_mins_from_ideal_lep'])\n",
    "y = result_df['lep_mins_from_ideal_lep']\n",
    "\n",
    "# Convert non-numeric columns to numeric where possible, and drop the rest\n",
    "X = X.apply(pd.to_numeric, errors='coerce')\n",
    "X = X.dropna(axis=1, how='any')\n",
    "\n",
    "# Drop rows where y is NaN\n",
    "X = X[~y.isna()]\n",
    "y = y.dropna()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Use RFE for feature selection\n",
    "selector = RFE(model, n_features_to_select=10, step=1)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X_train.columns[selector.support_]\n",
    "\n",
    "# Train the model with selected features\n",
    "model.fit(X_train[selected_features], y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test[selected_features])\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "\n",
    "# Display the selected features\n",
    "print(\"Selected features:\", selected_features)"
   ],
   "id": "94473bcb274214a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = filtered_df.corr()\n",
    "\n",
    "# Filter the correlation matrix to include only the correlations between causes and effects\n",
    "correlation_matrix = correlation_matrix.loc[interesting_causes, interesting_effects]\n",
    "\n",
    "# Plot the correlation matrix\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Matrix between Causes and Effects')\n",
    "plt.show()"
   ],
   "id": "bbc0e6e6acb0feff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filter columns that start with 'weather:' or 'sunrise:'\n",
    "filtered_columns = [col for col in result_df.columns if col.startswith('weather:') or col.startswith('sunrise:')]\n",
    "filtered_columns.append('sunExposure:lightDuringFirstTimeOutside')\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = result_df[filtered_columns].corr()\n",
    "\n",
    "# Get the correlation of 'lep_mins_from_ideal_lep' with other features\n",
    "lep_correlation = correlation_matrix['sunExposure:lightDuringFirstTimeOutside'].drop('sunExposure:lightDuringFirstTimeOutside')\n",
    "\n",
    "# Sort the correlations\n",
    "lep_correlation = lep_correlation.sort_values()\n",
    "\n",
    "# Plot the correlations\n",
    "plt.figure(figsize=(14, 10))\n",
    "lep_correlation.plot(kind='barh', color='skyblue')\n",
    "plt.xlabel('Correlation')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Correlation of sunExposure:lightDuringFirstTimeOutside with weather: and sunrise: features')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "86d5911f69b1f9e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filter the relevant columns\n",
    "filtered_df = result_df[['sunExposure:lightDuringFirstTimeOutside', 'sunrise:sunsetDurationSecs']]\n",
    "\n",
    "# Drop rows with missing values\n",
    "filtered_df = filtered_df.dropna()\n",
    "\n",
    "# Create a scatter plot with swapped axes\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(filtered_df['sunrise:sunsetDurationSecs'], filtered_df['sunExposure:lightDuringFirstTimeOutside'], color='skyblue')\n",
    "plt.xlabel('sunrise:sunsetDurationSecs')\n",
    "plt.ylabel('sunExposure:lightDuringFirstTimeOutside')\n",
    "plt.title('sunrise:sunsetDurationSecs vs sunExposure:lightDuringFirstTimeOutside')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "5c95c9c592b90cc9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train basic linear regression model",
   "id": "961d40ee0cf96c25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming result_df is your DataFrame\n",
    "X = result_df.drop(columns=['lep_mins_from_ideal_lep'])\n",
    "y = result_df['lep_mins_from_ideal_lep']\n",
    "\n",
    "# Convert non-numeric columns to numeric where possible, and drop the rest\n",
    "X = X.apply(pd.to_numeric, errors='coerce')\n",
    "X = X.dropna(axis=1, how='any')\n",
    "\n",
    "# Drop rows where y is NaN\n",
    "X = X[~y.isna()]\n",
    "y = y.dropna()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Use RFE for feature selection\n",
    "selector = RFE(model, n_features_to_select=10, step=1)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X_train.columns[selector.support_]\n",
    "\n",
    "# Train the model with selected features\n",
    "model.fit(X_train[selected_features], y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test[selected_features])\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "\n",
    "# Display the selected features\n",
    "print(\"Selected features:\", selected_features)"
   ],
   "id": "b1ed758bd15b4edd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train Catboost model",
   "id": "efe6229fab790c3f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Assuming result_df is your DataFrame\n",
    "X = result_df.drop(columns=['lep_mins_from_ideal_lep'])\n",
    "y = result_df['lep_mins_from_ideal_lep']\n",
    "\n",
    "# Convert non-numeric columns to numeric where possible, and drop the rest\n",
    "X = X.apply(pd.to_numeric, errors='coerce')\n",
    "X = X.dropna(axis=1, how='any')\n",
    "\n",
    "# Drop rows where y is NaN\n",
    "X = X[~y.isna()]\n",
    "y = y.dropna()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the CatBoost model\n",
    "model = CatBoostRegressor(\n",
    "    eval_metric='RMSE',  # Root Mean Squared Error\n",
    "    loss_function='RMSE',  # Loss function for regression\n",
    "    iterations=1000,  # Number of boosting iterations\n",
    "    learning_rate=0.03,  # Learning rate\n",
    "    depth=6,  # Depth of the tree\n",
    "    l2_leaf_reg=3,  # L2 regularization term on weights\n",
    "    early_stopping_rounds=50  # Early stopping rounds\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=100)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "\n",
    "# Display the feature importances\n",
    "feature_importances = model.get_feature_importance()\n",
    "selected_features = X_train.columns[feature_importances > 1]\n",
    "print(\"Selected features:\", selected_features)"
   ],
   "id": "22083fc8ca490ceb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def importances(md):\n",
    "    # Get feature importances\n",
    "    feature_importances = model.get_feature_importance()\n",
    "\n",
    "    # Create a DataFrame to display the feature importances\n",
    "    feature_names = X_train.columns\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': feature_importances\n",
    "    })\n",
    "    importance_df = importance_df[importance_df['Importance'] > 1]\n",
    "\n",
    "    # Sort the DataFrame by importance\n",
    "    importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Plot the feature importances\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.title(md.name + ' Feature Importances')\n",
    "    plt.gca().invert_yaxis()  # Invert y-axis to have the most important feature at the top\n",
    "    plt.show()\n",
    "\n",
    "importances(None)"
   ],
   "id": "162c6918291ccca2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e54252145ffafd9b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
