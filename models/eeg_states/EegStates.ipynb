{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# EEG States\n",
    "Training a model on manually labelled EEG data to find various states."
   ],
   "id": "b4f8c67b56e5d197"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import run_yasa\n",
    "import logging\n",
    "import mne\n",
    "import yasa\n",
    "import os\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from brainflow.board_shim import BoardShim, BoardIds\n",
    "from brainflow.data_filter import DataFilter\n",
    "log = lambda msg: logging.info(msg)\n"
   ],
   "id": "e7b3ecab1d3c58ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load data",
   "id": "4ea06b488bd85917"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "input_dir = \"C:\\\\dev\\\\play\\\\brainwave-data\"\n",
    "stats_df = pd.read_csv(input_dir + os.path.sep + \"stats.csv\")\n"
   ],
   "id": "4f67469e437f3c26",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a78c54b5b4a8d49"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T12:04:32.990154Z",
     "start_time": "2024-11-11T12:04:32.312620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models.eeg_states.eeg_states import load_events\n",
    "\n",
    "nights = load_events()"
   ],
   "id": "6c4c04dc7771c3fc",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T12:04:34.825239Z",
     "start_time": "2024-11-11T12:04:34.750716Z"
    }
   },
   "cell_type": "code",
   "source": "nights[\"event\"].value_counts()",
   "id": "910c3b8f8c32a4ca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event\n",
       "tired         187\n",
       "tired_long     74\n",
       "wired          48\n",
       "wired_long     24\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## EEG events - debounce\n",
    "A long event registers as an initial short event"
   ],
   "id": "cff6cc00556a4e01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T12:04:03.474727Z",
     "start_time": "2024-11-11T12:04:03.384416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models.eeg_states.eeg_states import debounce_events\n",
    "\n",
    "nights = debounce_events(nights)"
   ],
   "id": "947c7c0dc826c297",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T12:04:04.682857Z",
     "start_time": "2024-11-11T12:04:04.604229Z"
    }
   },
   "cell_type": "code",
   "source": "nights[\"event\"].value_counts()",
   "id": "5172a7edfc394525",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event\n",
       "tired         114\n",
       "tired_long     74\n",
       "wired          25\n",
       "wired_long     24\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## EEG events - find the duration",
   "id": "ff9bb76b42587bb7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from models.eeg_states.eeg_states import find_durations\n",
    "\n",
    "nights = find_durations(nights)"
   ],
   "id": "d64812afe7798de5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from models.eeg_states.eeg_states import convert_timestamps\n",
    "\n",
    "nights = convert_timestamps(nights)"
   ],
   "id": "a4484c1cc972c7c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load other data",
   "id": "de87c224e572de9e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for root, dirs, files in os.walk(input_dir):\n",
    "    for idx, dir_name in enumerate(dirs):\n",
    "        input_file = os.path.join(root, dir_name, \"raw.post_human.csv\")\n",
    "        if os.path.exists(input_file):\n",
    "            df = pd.read_csv(input_file)\n",
    "            dfs.append(df)\n",
    "\n",
    "yasa_df = pd.concat(dfs, ignore_index=True)"
   ],
   "id": "d6b0f77aa2bc14e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "yasa_df_orig = yasa_df.copy()\n",
    "assert yasa_df.index.is_unique, \"Index is not unique\""
   ],
   "id": "bdce19bdfb67f8b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "yasa_df.shape",
   "id": "7e2508ac3c2370f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "yasa_df['dayAndNightOf'].value_counts()",
   "id": "31f1100cc8b1a523",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "yasa_df[yasa_df['Epoch'] == 100].head()",
   "id": "47d8ee65d5109011",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prepare data - find if in state",
   "id": "cc619cdaf39c61cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sleep_events import convert_timestamps_to_uk\n",
    "\n",
    "convert_timestamps_to_uk(yasa_df, 'Timestamp', 'TimestampUK')"
   ],
   "id": "7394589ce5ebc76d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e19dc273404e6be3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from models.eeg_states.eeg_states import process_row\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Pre-filter the data as it takes ages\n",
    "first_timestamp_uk = nights['TimestampUK'].min()\n",
    "filtered_yasa_df = yasa_df[yasa_df['TimestampUK'] >= first_timestamp_uk]\n",
    "\n",
    "# Add new columns to yasa_df to store the epoch type\n",
    "yasa_df = filtered_yasa_df.copy() # defragment\n",
    "yasa_df['epoch_type'] = None\n",
    "yasa_df['matched_night_event'] = None\n",
    "\n",
    "# Iterate over each row in yasa_df\n",
    "for i, yasa_row in tqdm(yasa_df.iterrows(), total=yasa_df.shape[0]):\n",
    "    epoch_type, matched_night_event = process_row(yasa_row, nights)\n",
    "    yasa_df.at[i, 'epoch_type'] = epoch_type\n",
    "    yasa_df.at[i, 'matched_night_event'] = matched_night_event"
   ],
   "id": "6a5bf814e349a7f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "yasa_df['epoch_type'].value_counts()",
   "id": "290052673850b2a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from memory import garbage_collect\n",
    "\n",
    "garbage_collect(log)"
   ],
   "id": "937628b5487c5bff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from models.eeg_states.eeg_states_model import model_pipeline\n",
    "\n",
    "models_and_data = [model_pipeline('main', yasa_df, \"epoch_type\")]"
   ],
   "id": "b5642a9d8753a15",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from models.eeg_states.eeg_states_model import ModelAndData\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split(modelAndData: ModelAndData):\n",
    "    X_train_to_sleep, X_val_to_sleep, y_train_to_sleep, y_val_to_sleep = train_test_split(modelAndData.X, modelAndData.y, test_size=0.2, random_state=42)\n",
    "    modelAndData.X_train = X_train_to_sleep\n",
    "    modelAndData.y_train = y_train_to_sleep\n",
    "    modelAndData.X_val = X_val_to_sleep\n",
    "    modelAndData.y_val = y_val_to_sleep\n",
    "\n",
    "for md in models_and_data:\n",
    "    split(md)\n",
    "    print(f\"Training set size {md.name}: {len(md.X_train)}, validation set size: {len(md.X_val)}\")"
   ],
   "id": "235f5c5a88223170",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train Catboost model",
   "id": "7d10edf81dda7989"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T12:47:31.778876Z",
     "start_time": "2024-11-11T12:47:27.560732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "def train(md: ModelAndData):\n",
    "    md.model = CatBoostClassifier(\n",
    "        eval_metric='Logloss',    \n",
    "        loss_function='CrossEntropy',\n",
    "        iterations=1000,                # Number of boosting iterations\n",
    "        learning_rate=0.03,             # Learning rate\n",
    "        depth=6,                        # Depth of the tree\n",
    "        l2_leaf_reg=3,                  # L2 regularization term on weights\n",
    "        early_stopping_rounds=50        # Early stopping rounds\n",
    "    )\n",
    "\n",
    "    log(f\"Training model for {md.name}\")\n",
    "    md.model.fit(md.X_train, md.y_train, verbose=100)\n",
    "\n",
    "for md in models_and_data:\n",
    "    train(md)"
   ],
   "id": "c14d6afa4a5d36cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6704429\ttotal: 5.72ms\tremaining: 5.72s\n",
      "100:\tlearn: 0.0578121\ttotal: 422ms\tremaining: 3.75s\n",
      "200:\tlearn: 0.0155215\ttotal: 812ms\tremaining: 3.23s\n",
      "300:\tlearn: 0.0073068\ttotal: 1.22s\tremaining: 2.83s\n",
      "400:\tlearn: 0.0046872\ttotal: 1.58s\tremaining: 2.36s\n",
      "500:\tlearn: 0.0034136\ttotal: 1.98s\tremaining: 1.97s\n",
      "600:\tlearn: 0.0027426\ttotal: 2.38s\tremaining: 1.58s\n",
      "700:\tlearn: 0.0025003\ttotal: 2.79s\tremaining: 1.19s\n",
      "800:\tlearn: 0.0025003\ttotal: 3.22s\tremaining: 801ms\n",
      "900:\tlearn: 0.0025003\ttotal: 3.59s\tremaining: 394ms\n",
      "999:\tlearn: 0.0025003\ttotal: 3.94s\tremaining: 0us\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluate the model",
   "id": "670d0bb6a1ddb7c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_model(md: ModelAndData, model, X, y):\n",
    "    # Predict the target values using the trained model\n",
    "    predictions = model.predict(X)\n",
    "\n",
    "    # Calculate Mean Absolute Error (MAE)\n",
    "    mae = mean_absolute_error(y, predictions)\n",
    "\n",
    "    # Calculate Mean Squared Error (MSE)\n",
    "    mse = mean_squared_error(y, predictions)\n",
    "\n",
    "    # Calculate Root Mean Squared Error (RMSE)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    print(f\"{md.name} Mean Absolute Error (MAE): {mae}\")\n",
    "    print(f\"{md.name} Mean Squared Error (MSE): {mse}\")\n",
    "    print(f\"{md.name} Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "    return mae, mse, rmse\n",
    "\n",
    "def evaluate_classification_model(md: ModelAndData, X_train, y_train, X_val, y_val):\n",
    "    model = md.model\n",
    "    print(\"Evaluation for model: \", md.name)\n",
    "    # Evaluate the model on the training set\n",
    "    print(f\"{md.name} Training Set Evaluation:\")\n",
    "    train_mae, train_mse, train_rmse = evaluate_model(md, model, X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    print(f\"{md.name} Validation Set Evaluation:\")\n",
    "    val_mae, val_mse, val_rmse = evaluate_model(md, model, X_val, y_val)\n",
    "\n",
    "    val_train = model.predict(X_train)\n",
    "\n",
    "    train_results_df = pd.DataFrame({\n",
    "        'Actual': y_train,\n",
    "        'Predicted': val_train\n",
    "    })\n",
    "\n",
    "    cm_train = confusion_matrix(train_results_df['Actual'], train_results_df['Predicted'])\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm_train, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix (training)')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    # Predict the target values using the trained model\n",
    "    val_predictions = model.predict(X_val)\n",
    "    print(val_predictions)\n",
    "    \n",
    "    # Create a DataFrame with y_val and the predictions\n",
    "    val_results_df = pd.DataFrame({\n",
    "        'Actual': y_val,\n",
    "        'Predicted': val_predictions\n",
    "    })\n",
    "\n",
    "    cm_val = confusion_matrix(val_results_df['Actual'], val_results_df['Predicted'])\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm_val, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix (validation)')\n",
    "    plt.show()\n",
    "    \n",
    "for md in models_and_data:\n",
    "    evaluate_classification_model(md, md.X_train, md.y_train, md.X_val, md.y_val)\n",
    "#eval2(model_to_ready_to_sleep, X_train_to_ready_to_sleep, y_train_to_ready_to_sleep, X_val_to_ready_to_sleep, y_val_to_ready_to_sleep)"
   ],
   "id": "a56d0ddcd886037b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9d4ad40a406f60af"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "726fa3805710ebe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "models_and_data[0].model.predict_proba(models_and_data[0].X_val)",
   "id": "b8cbbe64187e7ae5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Most useful features",
   "id": "1f2c6052a49e86db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def importances(md: ModelAndData):\n",
    "    # Get feature importances\n",
    "    feature_importances = md.model.get_feature_importance()\n",
    "    \n",
    "    # Create a DataFrame to display the feature importances\n",
    "    feature_names = md.X_train.columns\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': feature_importances\n",
    "    })\n",
    "    importance_df = importance_df[importance_df['Importance'] > 1]\n",
    "    \n",
    "    # Sort the DataFrame by importance\n",
    "    importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "    # Plot the feature importances\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.title(md.name + ' Feature Importances')\n",
    "    plt.gca().invert_yaxis()  # Invert y-axis to have the most important feature at the top\n",
    "    plt.show()\n",
    "\n",
    "for md in models_and_data:\n",
    "    importances(md)"
   ],
   "id": "7d64768f1894c4b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Save model",
   "id": "953d8244ebe0700b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T12:47:36.880448Z",
     "start_time": "2024-11-11T12:47:36.790929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for md in models_and_data:\n",
    "    model_filename = f\"{md.name}_catboost_model.cbm\"\n",
    "    md.model.save_model(model_filename)\n",
    "    print(f\"Model saved to {model_filename}\")"
   ],
   "id": "879b18659800f852",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to main_catboost_model.cbm\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9437445ad83c8db5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
